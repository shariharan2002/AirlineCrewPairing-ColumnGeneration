{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e9af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab4deff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "class FLIGHT_LEG:\n",
    "    def __init__(self, origin, destination, dep_time,arr_time,flight_no,index,duration,day):\n",
    "        self.origin = origin\n",
    "        self.destination = destination\n",
    "        self.dep_time=dep_time\n",
    "        self.arr_time=arr_time\n",
    "        self.flight_no=flight_no\n",
    "        self.visited=False\n",
    "        self.index=index\n",
    "        self.duration=duration\n",
    "        self.day=day\n",
    "    def disp_flight_details(self):\n",
    "        print(\"Origin=\"+self.origin+\",Destination=\"+self.destination+\",DepTime=\"+str(self.dep_time)+\",ArrTime=\"+str(self.arr_time)+\",FlightNo\"+str(self.flight_no)+ \",Visited=\"+str(self.visited)+\",Index=\"+str(self.index)+\",Duration=\"+str(self.duration)+\",Day=\"+str(self.day))\n",
    "def time_converter(hr,minute,day):\n",
    "    total_time=hr*60+minute + (24*60)*day\n",
    "    return total_time\n",
    "\n",
    "def time_converter_for_duration(t):\n",
    "    total_time=t*60\n",
    "    return total_time\n",
    "\n",
    "\n",
    "def create_legs_object(df,days=2):\n",
    "    origin='a'\n",
    "    destination='a'\n",
    "    dep_time_char_hour='a'\n",
    "    dep_time_char_min='a'\n",
    "    arr_time_char_hour='a'\n",
    "    arr_time_char_min='a'\n",
    "    dep_time=0\n",
    "    arr_time=0\n",
    "    flight_no=\"a\"\n",
    "    legs=[]\n",
    "    count=0\n",
    "    no_of_days=days\n",
    "    for d in range(no_of_days):\n",
    "        for i in range(len(df)) :\n",
    "            origin=df.loc[i, \"Origin\"]\n",
    "            destination=df.loc[i, \"Destination\"]\n",
    "            dep_time_char_hour=df.loc[i, \"DepHour\"]\n",
    "            dep_time_char_min=df.loc[i, \"DepMin\"]\n",
    "            arr_time_char_hour=df.loc[i,\"ArrHour\"]\n",
    "            arr_time_char_min=df.loc[i, \"ArrMin\"]\n",
    "            dep_time=time_converter(int(dep_time_char_hour),int(dep_time_char_min),d)\n",
    "            arr_time=time_converter(int(arr_time_char_hour),int(arr_time_char_min),d)\n",
    "            flight_no=df.loc[i,'FlightNum']\n",
    "            duration=df.loc[i,'Duration'] #time_converter_for_duration(df.loc[i,'Duration'])\n",
    "            legs.append(FLIGHT_LEG(origin,destination,dep_time,arr_time,int(flight_no),count,duration,d))\n",
    "            count+=1\n",
    "    return legs\n",
    "def return_all_airports_dep_arr(legs):\n",
    "    \"\"\"\n",
    "    All_airports is just a set of union of all arriving and departing airports\n",
    "    airport_dep_flights is a dictionary of the following format : {'airport_code':[all departing flights from that airport code]}\n",
    "    Similarly airport_arr_flights\n",
    "    \"\"\"\n",
    "    all_airports=[]\n",
    "    for item in legs:\n",
    "        if item.origin not in all_airports:\n",
    "            all_airports.append(item.origin)\n",
    "        if item.destination not in all_airports:\n",
    "            all_airports.append(item.destination)\n",
    "\n",
    "    airport_dep_flights={}\n",
    "    airport_arr_flights={}\n",
    "\n",
    "    for airport in all_airports:\n",
    "        airport_dep_flights[airport]=[]\n",
    "        for item in legs:\n",
    "            if(item.origin==airport):\n",
    "                airport_dep_flights[airport].append(item)\n",
    "\n",
    "    for airport in all_airports:\n",
    "        airport_arr_flights[airport]=[]\n",
    "        for item in legs:\n",
    "            if(item.destination==airport):\n",
    "                airport_arr_flights[airport].append(item)\n",
    "    return all_airports,airport_arr_flights,airport_dep_flights\n",
    "def count_feasible_connections(adjacency_matrix):\n",
    "    \"\"\"\n",
    "    This is used as a counter/verifier to check how many feasible connections are present in the adjacency_matrix_of_connection\n",
    "    If adjacency_matrix[i][j]==1, then the count is updated.\n",
    "    \"\"\"\n",
    "    count=0\n",
    "    for i in range(len(adjacency_matrix)):\n",
    "        for j in range(len(adjacency_matrix[i])):\n",
    "            if adjacency_matrix[i][j]==1:\n",
    "                count+=1\n",
    "    return count\n",
    "\n",
    "\n",
    "def create_adjacency_matrix(legs):\n",
    " \n",
    "    adjacency_matrix_of_connections=[[0]*len(legs) for i in range(len(legs))]\n",
    "    for i in range(len(legs)):\n",
    "        for j in range(len(legs)):\n",
    "             if legs[i].destination==legs[j].origin and legs[j].dep_time-legs[i].arr_time>=20 and legs[j].dep_time-legs[i].arr_time<=180: \n",
    "                adjacency_matrix_of_connections[i][j]=1\n",
    "    #print(count_feasible_connections(adjacency_matrix_of_connections))\n",
    "    return adjacency_matrix_of_connections\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class Graph:\n",
    "\n",
    "    def __init__(self, vertices):\n",
    "        # No. of vertices\n",
    "        self.V = vertices\n",
    "\n",
    "        # default dictionary to store graph\n",
    "        self.graph = defaultdict(list)\n",
    "    # function to add an edge to graph\n",
    "    def addEdge(self, u, v):\n",
    "        self.graph[u].append(v)\n",
    "\n",
    "    '''A recursive function to print all paths from 'u' to 'd'.\n",
    "    visited[] keeps track of vertices in current path.\n",
    "    path[] stores actual vertices and path_index is current\n",
    "    index in path[]'''\n",
    "\n",
    "\n",
    "\n",
    "    def printAllPathsUtil(self, u, d, visited, path,dg):\n",
    "\n",
    "        # Mark the current node as visited and store in path\n",
    "        visited[u]= True\n",
    "        path.append(u)\n",
    "\n",
    "        # If current vertex is same as destination, then print\n",
    "        # current path[]\n",
    "        if u == d:\n",
    "            dg.duty_validity_checker_and_writer(path)\n",
    "        else:\n",
    "            # If current vertex is not destination\n",
    "            # Recur for all the vertices adjacent to this vertex\n",
    "            for i in self.graph[u]:\n",
    "                if visited[i]== False:\n",
    "                    self.printAllPathsUtil(i, d, visited, path,dg)\n",
    "\n",
    "        # Remove current vertex from path[] and mark it as unvisited\n",
    "        path.pop()\n",
    "        visited[u]= False\n",
    "\n",
    "\n",
    "    # Prints all paths from 's' to 'd'\n",
    "    def printAllPaths(self, s, d,dg):\n",
    "\n",
    "        # Mark all the vertices as not visited\n",
    "        visited =[False]*(self.V)\n",
    "\n",
    "        # Create an array to store paths\n",
    "        path = []\n",
    "\n",
    "        # Call the recursive helper function to print all paths\n",
    "        self.printAllPathsUtil(s, d, visited, path,dg)\n",
    "\n",
    "class Duty:\n",
    "    \"\"\"\n",
    "    Each duty period is essentially a Duty class\n",
    "    This sets of flight legs that comprise a DP are stored in the self.duty attribute\n",
    "    All other attributes like airtime etc are calculated using this self.duty attribute\n",
    "    \"\"\"\n",
    "    def __init__(self,duty):\n",
    "        self.duty=duty\n",
    "        self.airtime,self.total_duration=self.calculate_airtime_and_total_duration(self.duty)\n",
    "        self.duty_cost=self.calculate_duty_cost(self.duty)\n",
    "        self.flight_indices=self.calculate_flight_indices(self.duty)\n",
    "        self.duty_reduced_cost=self.calculate_duty_cost(self.duty)\n",
    "    def calculate_duty_cost(self,duty):\n",
    "        \"\"\"\n",
    "        The duty cost is obtained from Cynthia Barnhart s' textbook definition. \n",
    "        duty_cost=max(5/8* total_duration,flying_time, mintime=8hours)\n",
    "        \"\"\"\n",
    "        elapse_cost=(5/8)*self.total_duration\n",
    "        fly_cost=self.airtime\n",
    "        min_guar=8\n",
    "        duty_cost=max(elapse_cost,fly_cost,min_guar)\n",
    "        return duty_cost\n",
    "        \n",
    "    def calculate_airtime_and_total_duration(self,duty):\n",
    "        \"\"\"\n",
    "        Given a duty period, this calculates the total flying time(airtime) and the total duration(inclusive of wait time\n",
    "        between flights) and returns it\n",
    "        \"\"\"\n",
    "        airtime=0\n",
    "        total_duration=0\n",
    "        if len(duty)==1:\n",
    "            airtime=duty[0].duration\n",
    "            total_duration=0\n",
    "        else:\n",
    "            for i in range(len(duty)-1):\n",
    "                airtime+=duty[i].duration\n",
    "                total_duration+=(duty[i].duration+(duty[i+1].dep_time-duty[i].arr_time))\n",
    "            airtime+=duty[-1].duration\n",
    "            total_duration+=duty[-1].duration\n",
    "        return airtime,total_duration\n",
    "    def disp_duty_details(self):\n",
    "        for item in self.duty:\n",
    "            item.disp_flight_details()\n",
    "    def calculate_flight_indices(self,duty):\n",
    "        \"\"\"\n",
    "        Takes all flight indices related to a duty period and combines it into a list.\n",
    "        \"\"\"\n",
    "        flight_indices=[]\n",
    "        for leg in duty:\n",
    "            flight_indices.append(leg.index)\n",
    "        return flight_indices\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "class DutyGenerator:\n",
    "    def __init__(self,adj_matrix,duty_hour_limit=8*60, filename=\"2DayRoutingUltimateAir-190.txt\",legs=[]):\n",
    "        self.adjacency_matrix=adj_matrix\n",
    "        self.max_duty_hour_limit=duty_hour_limit\n",
    "        self.filename=filename\n",
    "        self.duty_list=[]\n",
    "        self.legs_count=len(self.adjacency_matrix)\n",
    "        self.graph=Graph(self.legs_count)\n",
    "        self.total_duty_count=0\n",
    "        self.feasible_connections=count_feasible_connections(self.adjacency_matrix)\n",
    "        self.legs=legs\n",
    "\n",
    "    def create_graph(self):\n",
    "        g = self.graph\n",
    "        for i in range(self.legs_count):\n",
    "            for j in range(self.legs_count):\n",
    "                if(self.adjacency_matrix[i][j]==1):\n",
    "                    g.addEdge(i,j)\n",
    "    def duty_validity_checker_and_writer(self,path):\n",
    "        \"\"\"\n",
    "        Any given duty has to satisfy the valid legal duty constraints/rules.\n",
    "        If the duty period is under the max_duty_hour_limit->then its added into the duty list.\n",
    "        \"\"\"\n",
    "        current_s=\"\"\n",
    "        total_time=0\n",
    "        temp_duty=[]\n",
    "        #print(path)\n",
    "        for element in path:\n",
    "            #current_s+=str(legs[element].flight_no)+\"-\" + str(legs[element].origin)+\"-\"+str(legs[element].destination) +\"-\"+str(legs[element].day)+\" \"\n",
    "            total_time+=self.legs[element].duration\n",
    "            temp_duty.append(self.legs[element])\n",
    "\n",
    "        if total_time<= self.max_duty_hour_limit:\n",
    "            self.duty_list.append(Duty(temp_duty.copy()))\n",
    "            self.total_duty_count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1c9256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leg_to_index_mapper(legs):\n",
    "    \"\"\"\n",
    "    A leg to index mapper is basically of the below format:\n",
    "    leg_to_index_mapper={leg.index:i}\n",
    "    index_to_leg_mapper={i:leg.index}\n",
    "    Both of these mappers are sometimes used, when the leg subset with which we are working is not the entire set.\n",
    "    When its just a subset, then brute indexing might lead to a whole lot of problems.\n",
    "    Mappers on the other hand can retain the original indexing. And hence these can avoid a lot of index out of range issues..etc\n",
    "    \"\"\"\n",
    "    mapper={}\n",
    "    for i in range(len(legs)):\n",
    "        mapper[legs[i].index]=i\n",
    "    return mapper\n",
    "\n",
    "def create_index_to_leg_mapper(legs):\n",
    "    mapper={}\n",
    "    for i in range(len(legs)):\n",
    "        mapper[i]=legs[i].index\n",
    "    return mapper\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52f446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80898929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count_feasible_connections(adjacency_matrix_of_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32253ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3685a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_departure_flights_and_organize(all_airports,airport_dep_flights):\n",
    "    start_airports=[]\n",
    "    end_airports=[]\n",
    "    for airport in all_airports:\n",
    "        start_airports.append(airport_dep_flights[airport])\n",
    "        end_airports.append(airport_dep_flights[airport])\n",
    "    return start_airports,end_airports\n",
    "\n",
    "def generate_duties(all_airports,airport_dep_flights,adjacency_matrix_of_connections,leg_to_index_mapper,legs): \n",
    "    \"\"\"\n",
    "    This function basically creates a graph(with adjacency_matrix_of_connections). Then it performs DFS over the graph and identifies\n",
    "    all valid duty periods.\n",
    "    \"\"\"\n",
    "    start_airports,end_airports=get_all_departure_flights_and_organize(all_airports,airport_dep_flights)\n",
    "    dg=DutyGenerator(adjacency_matrix_of_connections,8*60,\"UltimateAir2DayDutyPeriodList-SmallSchedule-10.txt\",legs) \n",
    "    dg.create_graph()\n",
    "    for start_airport in start_airports:\n",
    "        for s_flight in start_airport:\n",
    "            s=leg_to_index_mapper[s_flight.index]\n",
    "\n",
    "            for end_airport in end_airports:\n",
    "                for e_flight in end_airport:\n",
    "                    d=leg_to_index_mapper[e_flight.index]\n",
    "                    dg.graph.printAllPaths(s,d,dg)\n",
    "    return dg\n",
    "\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4372a879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17dc83e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1a8c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage_checker(pg,leg_to_index_mapper,legs):\n",
    "    \"\"\"\n",
    "    Coverage Matrix is a matrix, where the rows are indexed by flights_indices and the columns are indexed\n",
    "    by pairings. Each pairing consists of many flight indices. Therefore, coverage_matrix[flightIndex][pairingIndex]=1\n",
    "    If the pairing consists of that flight index, else 0\n",
    "    We also return the uncovered_flight_indices if the coverage_matrix does not cover all flights. \n",
    "    \"\"\"\n",
    "    coverage_matrix=[]\n",
    "    flight_coverage_checker=[]\n",
    "    for i in range(len(leg_to_index_mapper.values())):\n",
    "        temp=[]\n",
    "        flight_coverage_checker.append(0)\n",
    "        for j in range(len(pg.pairings)):\n",
    "            temp.append(0)\n",
    "        coverage_matrix.append(temp)\n",
    "    for j in range(len(pg.pairings)):\n",
    "        for indices in pg.pairings[j].flight_indices:\n",
    "            flight_coverage_checker[leg_to_index_mapper[indices]]+=1\n",
    "            coverage_matrix[leg_to_index_mapper[indices]][j]=1\n",
    "\n",
    "    # Checking if all flights have been covered at least under 1 pairing\n",
    "    flagger=True\n",
    "    non_covered_airports=[]\n",
    "    uncovered_flight_indices=[]\n",
    "    for i in range(len(flight_coverage_checker)):\n",
    "        if flight_coverage_checker[i]==0:\n",
    "            non_covered_airports.append(legs[i].origin)\n",
    "            #non_covered_airports.append(legs[i].destination)\n",
    "            non_covered_airports=list(set(non_covered_airports))\n",
    "            if flagger!=False:\n",
    "                flagger=False\n",
    "            \n",
    "            uncovered_flight_indices.append(i)\n",
    "    non_covered_airports=list(set(non_covered_airports).difference(set(pg.crew_base)))\n",
    "    if flagger==True:\n",
    "        print(\"Yay! All Flights Covered\")\n",
    "        return (True,coverage_matrix)\n",
    "    else:\n",
    "        print(\"Oh No! Not all Flights Covered\")\n",
    "        #print(\"The non covered airports are\",non_covered_airports)\n",
    "        print(\"\")\n",
    "        return (False,coverage_matrix,uncovered_flight_indices,leg_to_index_mapper)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d676e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_crew_bases_indices(crew_base,start):\n",
    "    crew_base_start={}\n",
    "    for i in range(len(crew_base)):\n",
    "        crew_base_start[crew_base[i]]=(start+i,start+len(crew_base)+i)\n",
    "    return crew_base_start\n",
    "\n",
    "#Original Function defined by me\n",
    "\n",
    "def duty_network(dg,crew_base,overnight_layover_constant=8*60):\n",
    "    \"\"\"\n",
    "    duty_network is matrix, that consists of duties as nodes. The edges are present between duties,\n",
    "    i.e duty_network[i][j] =1, only if the overnight layover time between 2 duties i and j is > 8 hours(or overnight_layover_constant)\n",
    "   \n",
    "    Once, the duty network is formed, any legal(valid) pairing, is formed between source and destination where:\n",
    "    Source:is a duty period node that starts at a crew bases\n",
    "    Destination:is a duty period node that ends at a crew base that started from source\n",
    "    \"\"\"\n",
    "    duty_network=[]\n",
    "    no_of_crew_bases=len(crew_base)\n",
    "    crew_bases_indices=return_crew_bases_indices(crew_base,len(dg.duty_list))\n",
    "    \n",
    "    for i in range(len(dg.duty_list)+(no_of_crew_bases*2)):\n",
    "        temp=[]\n",
    "        for j in range(len(dg.duty_list)+(no_of_crew_bases*2)):\n",
    "            temp.append(0)\n",
    "        duty_network.append(temp)\n",
    "        \n",
    "    for i in range(len(dg.duty_list)):\n",
    "        for j in range(len(dg.duty_list)):\n",
    "            if i!=j:\n",
    "                if (dg.duty_list[j].duty[0].dep_time-dg.duty_list[i].duty[-1].arr_time >= overnight_layover_constant) and (dg.duty_list[i].duty[-1].destination==dg.duty_list[j].duty[0].origin):\n",
    "                    duty_network[i][j]=1\n",
    "    #Connect Origin Airports to their appropriate crew start bases \n",
    "    for to_ in range(len(dg.duty_list)):\n",
    "        start_flight=dg.duty_list[to_].duty[0].origin\n",
    "        for keys,values in crew_bases_indices.items():\n",
    "            crew_base_from_index=values[0]\n",
    "            if keys==start_flight: #First flight of duty period s' origin has matched\n",
    "                duty_network[crew_base_from_index][to_]=1\n",
    "    #Connect Destination airports to their appropriate crew bases\n",
    "    for from_ in range(len(dg.duty_list)):\n",
    "        end_flight=dg.duty_list[from_].duty[-1].destination\n",
    "        for keys,values in crew_bases_indices.items():\n",
    "            crew_base_to_index=values[1]\n",
    "            if keys==end_flight: #Last flight of duty period s' destination has matched\n",
    "                duty_network[from_][crew_base_to_index]=1\n",
    "                \n",
    "    return duty_network,crew_bases_indices\n",
    "        \n",
    "            \n",
    "            \n",
    "# import numpy as np\n",
    "# from scipy.sparse import lil_matrix\n",
    "\n",
    "# def duty_network(dg, crew_base, overnight_layover_constant=8 * 60):\n",
    "#     no_of_crew_bases = len(crew_base)\n",
    "#     crew_bases_indices = return_crew_bases_indices(crew_base, len(dg.duty_list))\n",
    "\n",
    "#     # Create a sparse matrix using lil_matrix (List of List format)\n",
    "#     duty_network = lil_matrix((len(dg.duty_list) + (no_of_crew_bases * 2), len(dg.duty_list) + (no_of_crew_bases * 2)), dtype=int)\n",
    "\n",
    "#     for i in range(len(dg.duty_list)):\n",
    "#         #print(i)\n",
    "#         for j in range(len(dg.duty_list)):\n",
    "#             if i != j:\n",
    "\n",
    "#                 if (dg.duty_list[j].duty[0].dep_time - dg.duty_list[i].duty[-1].arr_time >= overnight_layover_constant) and (\n",
    "#                         dg.duty_list[i].duty[-1].destination == dg.duty_list[j].duty[0].origin):\n",
    "#                     duty_network[i, j] = 1\n",
    "\n",
    "#     # Connect Origin Airports to their appropriate crew start bases\n",
    "#     for to_ in range(len(dg.duty_list)):\n",
    "#         start_flight = dg.duty_list[to_].duty[0].origin\n",
    "#         for keys, values in crew_bases_indices.items():\n",
    "#             crew_base_from_index = values[0]\n",
    "#             if keys == start_flight:\n",
    "#                 duty_network[crew_base_from_index, to_] = 1\n",
    "\n",
    "#     # Connect Destination airports to their appropriate crew bases\n",
    "#     for from_ in range(len(dg.duty_list)):\n",
    "#         end_flight = dg.duty_list[from_].duty[-1].destination\n",
    "#         for keys, values in crew_bases_indices.items():\n",
    "#             crew_base_to_index = values[1]\n",
    "#             if keys == end_flight:\n",
    "#                 duty_network[from_, crew_base_to_index] = 1\n",
    "\n",
    "#     return duty_network, crew_bases_indices\n",
    "\n",
    "# import multiprocessing\n",
    "\n",
    "# def calculate_matrix_entry(args):\n",
    "#     i, j, dg, overnight_layover_constant = args\n",
    "#     print(i,j)\n",
    "#     if i != j:\n",
    "#         if (dg.duty_list[j].duty[0].dep_time - dg.duty_list[i].duty[-1].arr_time >= overnight_layover_constant) and (\n",
    "#                 dg.duty_list[i].duty[-1].destination == dg.duty_list[j].duty[0].origin):\n",
    "#             return (i, j, 1)\n",
    "#     return (i, j, 0)\n",
    "\n",
    "# def duty_network(dg, crew_base, overnight_layover_constant=8 * 60):\n",
    "#     no_of_crew_bases = len(crew_base)\n",
    "#     crew_bases_indices = return_crew_bases_indices(crew_base, len(dg.duty_list))\n",
    "\n",
    "#     # Create a pool of worker processes\n",
    "#     num_processes = multiprocessing.cpu_count()\n",
    "#     pool = multiprocessing.Pool(num_processes)\n",
    "\n",
    "#     args_list = [(i, j, dg, overnight_layover_constant) for i in range(len(dg.duty_list)) for j in range(len(dg.duty_list))]\n",
    "\n",
    "#     # Parallel computation of matrix entries\n",
    "#     result = pool.map(calculate_matrix_entry, args_list)\n",
    "\n",
    "#     # Close the pool to release resources\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "\n",
    "#     # Create a sparse matrix from the results\n",
    "#     duty_network = lil_matrix((len(dg.duty_list) + (no_of_crew_bases * 2), len(dg.duty_list) + (no_of_crew_bases * 2)), dtype=int)\n",
    "    \n",
    "#     for i, j, value in result:\n",
    "#         duty_network[i, j] = value\n",
    "\n",
    "#     # Connect Origin Airports to their appropriate crew start bases\n",
    "#     # Connect Destination airports to their appropriate crew bases (as in your original code)\n",
    "\n",
    "#     return duty_network, crew_bases_indices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e5c337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NXGRAPH_VISUALIZER(adj_matrix):\n",
    "    \"\"\"\n",
    "    This is to visualise the duty network or any adjacency matrix given as input.\n",
    "    The 2 adjancency matrices that we commonly use are: adjacency_matrix_of_connections \n",
    "    and duty_network\n",
    "    \"\"\"\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "    G=nx.DiGraph()\n",
    "    for i in range(len(adj_matrix)):\n",
    "        G.add_node(i)\n",
    "    for i in range(len(adj_matrix)):\n",
    "        for j in range(len(adj_matrix)):\n",
    "            if i!=j:\n",
    "                if adj_matrix[i][j]==1:\n",
    "                    G.add_edge(i,j)\n",
    "                    \n",
    "    nx.draw(G)\n",
    "    return G\n",
    "    \n",
    "#G=NXGRAPH_VISUALIZER(duty_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pairing:\n",
    "    def form_pairing(self,pairing):\n",
    "        self.pairing=pairing\n",
    "        self.duration_of_pairing=self.calculate_duration_of_pairing(self.pairing)\n",
    "        self.flight_indices=self.calculate_flight_indices(self.pairing)\n",
    "        self.TAFB=self.calculate_TAFB(self.pairing)\n",
    "        self.no_of_duty_periods=self.calculate_no_of_duty_periods(self.pairing)\n",
    "        self.total_duty_cost=self.calculate_total_duty_cost(self.pairing)\n",
    "        self.pairing_cost=self.calculate_pairing_cost(self.pairing,self.TAFB,self.no_of_duty_periods,self.total_duty_cost)\n",
    "        self.total_flying_time=self.calculate_total_flying_time(self.pairing)\n",
    "        self.total_elapse_time=self.calculate_total_elapse_time(self.pairing)\n",
    "        self.pairing_reduced_cost=self.calculate_reduced_cost(self.pairing)\n",
    "        \n",
    "    def __init__(self,pairing=[]):\n",
    "        self.pairing=[]\n",
    "        self.duration_of_pairing=0\n",
    "        self.flight_indices=[]\n",
    "        self.TAFB=0\n",
    "        self.no_of_duty_periods=0\n",
    "        self.total_duty_cost=0\n",
    "        self.pairing_cost=0\n",
    "        self.total_flying_time=0\n",
    "        self.total_elapse_time=0\n",
    "        self.pairing_reduced_cost=0\n",
    "        if len(pairing)!=0:\n",
    "            self.form_pairing(pairing)\n",
    "        \n",
    "    def calculate_duration_of_pairing(self,pairing):\n",
    "        days=int(((pairing[-1].duty[-1].arr_time-pairing[0].duty[0].dep_time)/60)/24)\n",
    "        return days\n",
    "        \n",
    "    def calculate_flight_indices(self,pairing):\n",
    "        flight_indices=[]\n",
    "        for item in pairing:\n",
    "            duty=item.duty\n",
    "            for flight in duty:\n",
    "                flight_indices.append(flight.index)\n",
    "        return flight_indices\n",
    "                \n",
    "    def calculate_TAFB(self,pairing):\n",
    "        TAFB=int(((pairing[-1].duty[-1].arr_time-pairing[0].duty[0].dep_time)/60)/24)\n",
    "        return TAFB\n",
    "    \n",
    "    def calculate_no_of_duty_periods(self,pairing):\n",
    "        return len(pairing)\n",
    "    \n",
    "    def calculate_total_duty_cost(self,pairing):\n",
    "        cost=0\n",
    "        for duty in pairing:\n",
    "            cost+=duty.duty_cost\n",
    "        return cost\n",
    "    \n",
    "    def calculate_pairing_cost(self,pairing,TAFB,no_of_duty_periods,total_duty_cost):\n",
    "        fp=10\n",
    "        mg=10\n",
    "        cost=max(fp*TAFB,mg*no_of_duty_periods,total_duty_cost)\n",
    "        link_cost=0\n",
    "        constant_overnight_layover_cost_per_hour=100\n",
    "        if len(pairing)==1:\n",
    "            link_cost=0\n",
    "        else:\n",
    "            for i in range(len(pairing)-1):\n",
    "                duty1=pairing[i].duty\n",
    "                duty2=pairing[i+1].duty\n",
    "                overnight_layover_time=duty2[0].dep_time-duty1[-1].arr_time\n",
    "                overnight_layover_time_cost=constant_overnight_layover_cost_per_hour*overnight_layover_time\n",
    "                link_cost+=overnight_layover_time_cost\n",
    "        total_pairing_cost=cost+link_cost\n",
    "        return total_pairing_cost\n",
    "    \n",
    "    def calculate_total_flying_time(self,pairing):\n",
    "        total_flying_time=0\n",
    "        for item in pairing:\n",
    "            total_flying_time+=item.airtime\n",
    "        return total_flying_time\n",
    "    \n",
    "    def calculate_total_elapse_time(self,pairing):\n",
    "        total_elapse_time=0\n",
    "        if len(pairing)!=0:\n",
    "            for i in range(len(pairing)-1):\n",
    "                total_elapse_time+=pairing[i].total_duration\n",
    "                total_elapse_time+=(pairing[i+1].duty[0].dep_time-pairing[i].duty[-1].arr_time) # add overnight layover time\n",
    "            total_elapse_time+=pairing[-1].total_duration\n",
    "        else:\n",
    "            total_elapse_time+=pairing[0].total_duration\n",
    "        return total_elapse_time\n",
    "    \n",
    "    def calculate_reduced_cost(self,pairing):\n",
    "        p_reduced_cost=0\n",
    "        for i in range(len(pairing)):\n",
    "            p_reduced_cost+=pairing[i].duty_reduced_cost\n",
    "        return p_reduced_cost\n",
    "            \n",
    "        \n",
    "        \n",
    "    def disp_pairing_details(self):\n",
    "        s=\"\"\n",
    "        for item in self.pairing:\n",
    "            for leg in item.duty:\n",
    "                s+=\"(\"+\"IND=\"+str(leg.index)+\",\"+str(leg.flight_no)+\",\"+str(leg.origin)+\"=\"+str(leg.destination)+\",\"+str(leg.day) +\")\"+ \"->\"\n",
    "        print(s)\n",
    "    def form_label_list(self):\n",
    "        label_list=(self.TAFB,self.no_of_duty_periods,self.pairing_reduced_cost,self.pairing_cost,self.total_flying_time,self.total_elapse_time)\n",
    "        #label_list=(self.pairing_reduced_cost,self.pairing_cost)\n",
    "        #label_list=(self.TAFB,self.total_duty_cost,self.total_flying_time,self.no_of_duty_periods)\n",
    "        #print(label_list)\n",
    "        return label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e206855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    def __init__(self,index,duty_index,typ,neighbors):\n",
    "        \"\"\"\n",
    "        A node class is defined in order to make SPPRC more organized. Each node has index, duty_index, neighbors, type and labels \n",
    "        as properties.\n",
    "        The typ has usually 3 options -> s, t, d  .. where s means start, t means destination, d means duty.\n",
    "        |S| = |crew_bases| and |T| =|crew_bases|\n",
    "        S_crew_base is connected to all duty periods starting with that specific crew_base\n",
    "        All duty periods ending with that specific crew base in connected to T_crew_base\n",
    "        Hence, a valid crew pairing is represented as a path from S_Crew_base to E_crew_base satisfying many rules\n",
    "    \n",
    "        \"\"\"\n",
    "        self.index=index\n",
    "        self.duty_index=duty_index\n",
    "        self.neighbors=neighbors\n",
    "        self.typ=typ\n",
    "        self.labels=[]\n",
    "\n",
    "def feasibility_check(p,d,pairing_legality_params):\n",
    "    \"\"\"\n",
    "    A duty(d) needs to be added to an existing(p). Then new_p is formed. This new_p is checked if it satisifes all rules\n",
    "    and legalities(for eg: Time Away from Base, Total Flying time and Max no. of Duty Periods)\n",
    "    Only if the new_p satisfies all the legality rules, only then an indicator True with the new pairing shall be returned\n",
    "    Else, False shall be returned\n",
    "    \"\"\"\n",
    "    new_p=p.pairing\n",
    "    new_p.append(d)\n",
    "    new_p=Pairing(new_p)\n",
    "    #Feasibility checking !\n",
    "    #print(new_p.form_label_list())\n",
    "    if new_p.TAFB<=pairing_legality_params['TAFB'] and new_p.total_flying_time<=pairing_legality_params['MAXFLYINGTIME'] and new_p.no_of_duty_periods<=pairing_legality_params['MAXDUTYPERIODS']:\n",
    "        return (True,new_p)\n",
    "    else:\n",
    "        return (False,[])\n",
    "    \n",
    "def comparer(tuple1,tuple2):\n",
    "    \"\"\"\n",
    "    2 tuples that are N dimensional are compared.\n",
    "    Say Ti=(di1,di2....,din)\n",
    "    Say Tj=(dj1,dj2....,djn)\n",
    "    Here Ti is the entering resource list or the new resource list that has to be compared against all existing resource lists\n",
    "    which is Tj\n",
    "    If any resource of Ti say di_index <= dj_index of Tj, then a True is appended, which essentially means Tj cannot dominate Ti\n",
    "    However, if not even 1 resource Ti can dominate Tj then it means Tj entirely dominates Ti and therefore Ti need not be added\n",
    "    to labels and can be ignored from future computations.\n",
    "    \"\"\"\n",
    "    comparer=[]\n",
    "    #print(tuple1,tuple2)\n",
    "    for i in range(len(tuple1)):\n",
    "        if tuple1[i]<=tuple2[i]:\n",
    "            comparer.append(True)\n",
    "            break\n",
    "        else:\n",
    "            comparer.append(False)\n",
    "    if True in comparer:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def dominate(entering_resource_list,labels):\n",
    "    \"\"\"\n",
    "    For each node, there exists many labels. The entering resource list has to be compared against all labels of a particular node\n",
    "    If every label dominates the entering resource list, then it is ignored. However, if the entering resource list dominates\n",
    "    atleast one label of all labels present in that node in atleast 1 resource aspect, then it cannot be ignored and has to be\n",
    "    accounted for.\n",
    "    The comparison/domination check between the resources of 2 lists is done by comparer() function[Note: the comparer function\n",
    "    sends entering_resource_list,old_resource_list as parameters]\n",
    "    \"\"\"\n",
    "    entering_resource_list=entering_resource_list.form_label_list()\n",
    "    label_check=[]\n",
    "    for label in labels:\n",
    "        old_resource_list=label[1].form_label_list()\n",
    "        if comparer(entering_resource_list,old_resource_list)==True:\n",
    "            label_check.append(True)\n",
    "            break\n",
    "        else:\n",
    "            label_check.append(False)\n",
    "    if True in label_check or len(label_check)==0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb372cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943aa82a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36355dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SPPRC(airport_letter_code,duty_network,crew_bases_indices,s_nodes_dict,t_nodes_dict,dg):\n",
    "    \"\"\"\n",
    "    This is the SPPRC Function code. The SPPRC function is iterated through each crew base in order to generate paths.\n",
    "    \"\"\"\n",
    "    node_dict={}\n",
    "    for i in range(len(duty_network)):\n",
    "        neighbors=[]\n",
    "        for j in range(len(duty_network[i])):\n",
    "            if duty_network[i][j]==1:\n",
    "                neighbors.append(j)\n",
    "        duty_index=i\n",
    "        if i <len(dg.duty_list):\n",
    "            typ='d'\n",
    "        else:\n",
    "            if i in s_nodes_dict.values():\n",
    "                typ='s'\n",
    "            elif i in t_nodes_dict.values():\n",
    "                typ='t'\n",
    "\n",
    "        node_dict[i]=node(i,duty_index,typ,neighbors)\n",
    "    start=crew_bases_indices[airport_letter_code][0]\n",
    "    U=[[start,Pairing(),start]]\n",
    "    pairing_legality_params={'TAFB':5,'MAXFLYINGTIME':50*60,'MAXDUTYPERIODS':8}\n",
    "    stopping_criterion_pairings_count=10*100\n",
    "    ct=0\n",
    "    end=crew_bases_indices[airport_letter_code][1]\n",
    "    while len(U) !=0:\n",
    "        #SPPRC Limiting/Stopping Criterion to Control SPPRC Flow\n",
    "        if len(node_dict[end].labels) >= stopping_criterion_pairings_count:\n",
    "            return node_dict[end].labels\n",
    "        else:\n",
    "            current_item=U.pop(0)\n",
    "            current_node=current_item[0]\n",
    "            current_pairing=current_item[1]\n",
    "            if dominate(current_pairing,node_dict[current_node].labels)==True:\n",
    "                node_dict[current_node].labels.append(current_item)\n",
    "                for extension in node_dict[current_node].neighbors:\n",
    "                    if node_dict[extension].typ!='t':\n",
    "                        f=feasibility_check(Pairing(current_pairing.pairing.copy()),dg.duty_list[node_dict[extension].duty_index],pairing_legality_params)\n",
    "                        if f[0]==True:\n",
    "                            U.append([extension,f[1],current_node])\n",
    "                    elif node_dict[extension].typ=='t':\n",
    "                        U.append([extension,current_pairing,current_node])\n",
    "    end=crew_bases_indices[airport_letter_code][1]\n",
    "    return node_dict[end].labels\n",
    "\n",
    "def calculate_negative_reduced_cost(pairing,dual_values):\n",
    "    dual_costs=0\n",
    "    for flight_index in pairing.flight_indices:\n",
    "        dual_costs+=dual_values[flight_index]\n",
    "    \n",
    "    if pairing.pairing_cost-dual_costs <=0:\n",
    "        print(pairing.pairing_cost-dual_costs,\"BRO\")\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def process_labels_and_collect_pairings(PG,labels,dual_values):\n",
    "    for label in labels:\n",
    "        checker=False\n",
    "        for pairing in PG:\n",
    "            if sorted(pairing.flight_indices)==sorted(label[1].flight_indices):\n",
    "                checker=True\n",
    "        if checker==False: \n",
    "            if calculate_negative_reduced_cost(label[1],dual_values)==True:\n",
    "                PG.append(label[1])\n",
    "    return PG\n",
    "\n",
    "def form_duty_network(dg,crew_base):\n",
    "    \"\"\"\n",
    "    This is just a helper function for duty_network()\n",
    "    It returns the dutyNetwork, crew_bases_indices, s_nodes_dict, t_nodes_dict.\n",
    "    The crew_bases_indices is a dictionary that has the format: {\"airport_code\":[start_node_index,end_node_index]}\n",
    "    start_node_index is basically the index of the node in the duty_network that has the index responsible for itself connecting to all \n",
    "    duty periods starting with that crew base\n",
    "    Same goes with the end_node_index->responsible for all duty periods ending at a particular crew base to connect itself with the appropriate\n",
    "    corresponding end_node crew base\n",
    "    Eg:The start_node corres to JFK is connected to  All DPs that start with JFK as its crew base.\n",
    "    Similarly, all DPs ending with JFK are connected to end_node corres to JFK.\n",
    "    s_nodes_dict contains the foll format {\"airport_code\":start_index}\n",
    "    t_nodes_dict contains the foll format {\"airport_code\":end_index}\n",
    "    \n",
    "    \"\"\"\n",
    "    dutyNetwork,crew_bases_indices=duty_network(dg,crew_base)\n",
    "    s_nodes_dict={}\n",
    "    t_nodes_dict={}\n",
    "    for k,v in crew_bases_indices.items():\n",
    "        s_nodes_dict[k]=v[0]\n",
    "        t_nodes_dict[k]=v[1]\n",
    "    return dutyNetwork,crew_bases_indices,s_nodes_dict,t_nodes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa284a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a37f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairingsGenerator:\n",
    "    def __init__(self,pairings=[]):\n",
    "        self.pairings=[]\n",
    "        self.overnight_rest=8*60\n",
    "        #self.crew_base=['JFK','ATL','LAX','SFO','ORD','BOS','MIA']\n",
    "        self.crew_base=['DEL', 'BLR', 'BOM', 'HYD', 'CCU', 'MAA', 'AMD', 'PNQ', 'GAU', 'LKO', 'VNS', 'BBI', 'COK', 'PAT', 'GOI', 'JAI', 'SXR', 'IXE', 'IMF']\n",
    "        if len(pairings)!=0:\n",
    "            self.form_pair_gen(pairings)\n",
    "    def form_pair_gen(self,pairings):\n",
    "        self.pairings=pairings\n",
    "        self.overnight_rest=8*60\n",
    "        #self.crew_base=['JFK','ATL','LAX','SFO','ORD','BOS','MIA']\n",
    "        self.crew_base=['DEL', 'BLR', 'BOM', 'HYD', 'CCU', 'MAA', 'AMD', 'PNQ', 'GAU', 'LKO', 'VNS', 'BBI', 'COK', 'PAT', 'GOI', 'JAI', 'SXR', 'IXE', 'IMF']\n",
    "        \n",
    "    def generate_1_day_pairings(self,duty_list):\n",
    "        for i in range(len(duty_list)):\n",
    "            if duty_list[i].duty[0].origin in self.crew_base and duty_list[i].duty[-1].destination in self.crew_base and duty_list[i].duty[0].origin==duty_list[i].duty[-1].destination:\n",
    "                self.pairings.append(Pairing([duty_list[i]]))\n",
    "                             \n",
    "    def generate_2_day_pairings(self,duty_list):\n",
    "        for i in range(len(duty_list)):\n",
    "            for j in range(len(duty_list)):\n",
    "                if i!=j:\n",
    "                    if duty_list[i].duty[-1].destination==duty_list[j].duty[0].origin:\n",
    "                        if duty_list[i].duty[0].origin in self.crew_base and duty_list[j].duty[-1].destination in self.crew_base and duty_list[i].duty[0].origin==duty_list[j].duty[-1].destination:\n",
    "                            if duty_list[j].duty[0].dep_time-duty_list[i].duty[-1].arr_time>=self.overnight_rest and duty_list[j].duty[0].dep_time>=duty_list[i].duty[-1].arr_time:\n",
    "                                self.pairings.append(Pairing([duty_list[i],duty_list[j]]))\n",
    "    def generate_short_round_trip_pairings(self,legs):\n",
    "        \"\"\"\n",
    "        This function is mainly decide to try and quickly cover flights that can be covered by roundtrips\n",
    "        It takes a start flight from a crew base and then tries to find a return flight back to the same crew base.\n",
    "        If a return flight is found. Then the pairing is terminated and no other flight is added.\n",
    "        This is not optimal but it is designed to cover a large set of flights.\n",
    "        Eg: MAA-TRZ and TRZ-MAA form a round trip pairings.\n",
    "        \"\"\"\n",
    "        for crew_base in self.crew_base:\n",
    "            start_airport=crew_base\n",
    "            end_airport=crew_base\n",
    "            for start_leg in legs:\n",
    "                if start_leg.origin == start_airport:\n",
    "                    start_leg_origin=start_leg.origin\n",
    "                    start_leg_destination=start_leg.destination\n",
    "                    for end_leg in legs:\n",
    "                        temp_duty=[]\n",
    "                        if end_leg.origin==start_leg_destination and end_leg.dep_time-start_leg.arr_time >=20 and end_leg.dep_time-start_leg.arr_time <=240 and end_leg.destination==end_airport:\n",
    "                            temp_duty.append(start_leg)\n",
    "                            temp_duty.append(end_leg)\n",
    "                            duty=Duty(temp_duty)\n",
    "                            self.pairings.append(Pairing([duty]))\n",
    "            \n",
    "                                                     \n",
    "\n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4bb884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_objective_function_coefficients(pg,revised=True):\n",
    "    objective_function_coefficients=[]\n",
    "    for pairing in pg.pairings:\n",
    "        if pairing.duration_of_pairing==0:\n",
    "            objective_function_coefficients.append(1)\n",
    "        elif pairing.duration_of_pairing==1:\n",
    "            objective_function_coefficients.append(3)\n",
    "        elif pairing.duration_of_pairing==2:\n",
    "            objective_function_coefficients.append(6)\n",
    "        elif pairing.duration_of_pairing==3:\n",
    "            objective_function_coefficients.append(9)\n",
    "        elif pairing.duration_of_pairing==4:\n",
    "            objective_function_coefficients.append(12)\n",
    "    objective_function_coefficients_revised=[]\n",
    "    for pairing in pg.pairings:\n",
    "        objective_function_coefficients_revised.append(pairing.pairing_cost)\n",
    "    if revised==True:\n",
    "        return objective_function_coefficients_revised\n",
    "    else:\n",
    "        return objective_function_coefficients\n",
    "\n",
    "def create_and_solve_model(pg,leg_to_index_mapper,legs,IP=False):\n",
    "    coverage=coverage_checker(pg,leg_to_index_mapper,legs)\n",
    "    if coverage[0]==False:\n",
    "        print(\"Not Possible To Proceed Until all flights covered!\")\n",
    "        print(\"Ending .....\")\n",
    "        return\n",
    "    coverage_matrix=coverage[1]\n",
    "    objective_function_coefficients=get_objective_function_coefficients(pg)\n",
    "    from docplex.mp.model import Model\n",
    "    airline_cp_model = Model('Airline Crew Pairing Model')\n",
    "    if IP==False:\n",
    "        x = airline_cp_model.continuous_var_list(len(pg.pairings), name=\"x\")\n",
    "    else:\n",
    "        x = airline_cp_model.binary_var_list(len(pg.pairings), name=\"x\")\n",
    "    #print(x,len(legs))\n",
    "    for i in range(len(legs)):\n",
    "        airline_cp_model.add_constraint(sum(coverage_matrix[i][j]*x[j] for j in range(len(pg.pairings))) >= 1, 'airline')\n",
    "    obj_fn=sum(objective_function_coefficients[i]*x[i] for i in range(len(pg.pairings)))\n",
    "    airline_cp_model.set_objective(\"min\",obj_fn)\n",
    "# !!!!!!!!!! THE BELOW ARE IMPORTANT PRINT STATEMENTS DO NOT JUST DELETE THEM !!!!!!!!!!!!!!\n",
    "#     print(\"**** \\t AIRLINE CREW PAIRING MODEL INFORMATION \\t ****\")\n",
    "#     airline_cp_model.print_information()\n",
    "    print(\"**** \\t SOLVING \\t ****\")\n",
    "    sol=airline_cp_model.solve()\n",
    "#     print(\"**** \\t SOLVED \\t ****\")\n",
    "#     print(\"**** !!!! \\n\\n\\t SOLUTION DETAILS \\t\\n\\n !!!! ****\")\n",
    "#     airline_cp_model.print_solution()\n",
    "    return sol,airline_cp_model,x\n",
    "\n",
    "\n",
    "\n",
    "def return_pairing_information(pg,airline_cp_model,x):\n",
    "    pairing_solution_indices=[]\n",
    "    for i in range(len(pg.pairings)):\n",
    "        if airline_cp_model.solution.get_values(x)[i]==1:\n",
    "            pairing_solution_indices.append(i)\n",
    "    return pairing_solution_indices\n",
    "\n",
    "def print_pairing_information(pg,pairing_solution_indices):\n",
    "    for index in pairing_solution_indices:\n",
    "        print(\"PAIRINGINDEX=\",index,\"---->\",end='')\n",
    "        pg.pairings[index].disp_pairing_details()\n",
    "        print()\n",
    "        \n",
    "def return_dual_values(airline_cp_model):\n",
    "    dual_values=airline_cp_model.dual_values(airline_cp_model.find_matching_linear_constraints('airline'))\n",
    "    flight_duals={}\n",
    "    for i in range(len(dual_values)):\n",
    "        flight_duals[i]=dual_values[i]\n",
    "    return flight_duals\n",
    "\n",
    "def print_dual_values(dual_values,legs):\n",
    "    for k,v in dual_values.items():\n",
    "        print(\"FlightIndex=\",k,\"-->DualValue-->\",dual_values[k],\"||||| DETAILS=\",end='')\n",
    "        legs[k].disp_flight_details()\n",
    "        print()\n",
    "        \n",
    "def modify_duty_costs(dual_values,dg):\n",
    "    \"\"\"\n",
    "    This function is used to modify the duty values after the column generation iteration returns some pairings.\n",
    "    Basically, it modifes the duty costs so that revised new pairings are obtained via SPPRC\n",
    "    \"\"\"\n",
    "    for i in range(len(dg.duty_list)):\n",
    "        current_duty_object=dg.duty_list[i]\n",
    "        current_duty=current_duty_object.duty\n",
    "        current_duty_flight_indices=current_duty_object.flight_indices\n",
    "        for flight_index in current_duty_flight_indices:\n",
    "            current_duty_object.duty_reduced_cost+=dual_values[flight_index]\n",
    "            #current_duty_object.duty_cost+=dual_values[flight_index]\n",
    "    return dg\n",
    "\n",
    "def default_model_return_function(sol,airline_cp_model,x,pg):\n",
    "    # !!!!!!!!!! THE BELOW ARE IMPORTANT PRINT STATEMENTS DO NOT JUST DELETE THEM !!!!!!!!!!!!!!\n",
    "    if sol is None:\n",
    "        print(\"\\n\\n\\n\\n !!!! Infeasible Oh No !!!!\\n\\n\\n\\n\")\n",
    "    else:\n",
    "        print(\"\\n\\n\\n\\n!!!! Feasible Yes !!!! :) \\n\\n\\n\\n \")\n",
    "        #print(\"\\n\\n\\n\\n!!!! PAIRING DETAILS !!!! \\n\\n\\n\\n \")\n",
    "        pairing_solution_indices=return_pairing_information(pg,airline_cp_model,x)\n",
    "        #print_pairing_information(pg,pairing_solution_indices)\n",
    "        #print(\"\\n\\n\\n\\n Dual Information \\n\\n\\n\\n\")\n",
    "        dual_values=return_dual_values(airline_cp_model)\n",
    "        #print_dual_values(dual_values,legs)\n",
    "    return pairing_solution_indices,dual_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5dc41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flight_coverage_status(legs):\n",
    "    \"\"\"\n",
    "    The flight_coverage_status initializes a dictionary to values as False for all legs present in legs.\n",
    "    This status dict is used often to check if all flights have been covered or not\n",
    "    or i.e if any flight is not yet covered.\n",
    "    \"\"\"\n",
    "    flight_coverage_status={}\n",
    "    for i in range(len(legs)):\n",
    "        flight_coverage_status[legs[i].index]=False\n",
    "    return flight_coverage_status\n",
    "# def form_index_updated_pairing(entering_pairing,legs,index_to_leg_mapper,leg_to_index_mapper):\n",
    "#     new_pairing=[]\n",
    "#     pairing=entering_pairing.pairing\n",
    "#     for i in range(len(pairing)):\n",
    "#         current_duty=pairing[i].duty\n",
    "#         temp_duty=[]\n",
    "#         for j in range(len(current_duty)):\n",
    "#             current_leg=current_duty[j]\n",
    "#             revised_leg_index=leg_to_index_mapper[current_leg.index]\n",
    "#             revised_leg=legs[revised_leg_index]\n",
    "#             temp_duty.append(revised_leg)\n",
    "#         temp_duty=Duty(temp_duty)\n",
    "#         new_pairing.append(temp_duty)\n",
    "#     new_pairing=Pairing(new_pairing)\n",
    "#     return new_pairing\n",
    "def update_pairing_set(PG,pg,pairing_solution_indices,legs,index_to_leg_mapper,leg_to_index_mapper):\n",
    "    \"\"\"\n",
    "    The pg.pairings contains a new set of pairings that decide to enter the original list\n",
    "    And the PG.pairings contains the old/original set of pairings. \n",
    "    if however, the sorted flight indices of a new pairing matches with the sorted flight indices of any\n",
    "    existing pairing, it essentially means the pairing already exists, and therefore the new pairing can\n",
    "    be ignored\n",
    "    This function is mainly designed so that duplicates do not enter the original PG list.\n",
    "    \"\"\"\n",
    "    for index in pairing_solution_indices:\n",
    "        new_pairing=pg.pairings[index]\n",
    "        checker=True\n",
    "        for existing_pairing in PG:\n",
    "            if sorted(existing_pairing.flight_indices)==sorted(new_pairing.flight_indices):\n",
    "                checker=False\n",
    "        if checker==True:\n",
    "            PG.append(new_pairing)\n",
    "    return PG\n",
    "\n",
    "def update_flight_coverage_status(flight_coverage_status,flight_legs_chosen):\n",
    "    \"\"\"\n",
    "    For each leg in flight_legs_chosen, the flight coverage status of that particular leg is updated from\n",
    "    False to True.\n",
    "    \"\"\"\n",
    "    for leg in flight_legs_chosen:\n",
    "        flight_coverage_status[leg.index]=True\n",
    "    return flight_coverage_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb7941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17089567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd8af6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de254e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dd6215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_update_flight_coverage_status(pairings,coverage_status):\n",
    "    \"\"\"\n",
    "    Each pairing consists of many duties, and each duty consist of many flight indices/flights.\n",
    "    In order to update the flight_coverage_status, one takes in a list of pairings, and for all those\n",
    "    flights contained in the pairings, the indicator is updated to TRUE.    \n",
    "    The constant updation of flight_coverage_status is needed since, it would then help us determine which\n",
    "    flights are still uncovered and how to continue the divide and cover/any other heuristic. Also, if all the\n",
    "    flights are True, then it means all flight have been covered by the set of pairings given and therefore, \n",
    "    we can stop Divide and Cover.\n",
    "    \"\"\"\n",
    "    for pairing in pairings:\n",
    "        for index in pairing.flight_indices:\n",
    "            coverage_status[index]=True\n",
    "    return coverage_status\n",
    "def init_update_pairing_list(pairings,PG):\n",
    "    \"\"\"\n",
    "    In every iteration of Divide and Cover/Divide and Cover Controller new pairings are generated. These need to be added\n",
    "    to the global PG Set. This function helps in doing so. This function is mainly used in the Divide and Cover Controller code.\n",
    "    \"\"\"\n",
    "    for pairing in pairings:\n",
    "        PG.append(pairing)\n",
    "    return PG\n",
    "def update_flight_list(updated_flight_legs,legs,global_flight_legs_copy,flight_coverage_status,K,main_iter):\n",
    "    \"\"\"\n",
    "    This takes in as input \"updated_flight_legs, legs, global_flight_legs_copy, flight_coverage_status, K, main_iter\"\n",
    "    1. For all flights that are not covered(i.e flight_coverage_status[index]=False), it takes into consideration\n",
    "    the Origin and Destination airport. Also these uncovered flights are added to updated_flight_legs\n",
    "    2. Then, We form a set called uncov_airports\n",
    "    3. For the airports, present in uncov_airports, we find out all flights that have either the origin or destination as \n",
    "    one of these airports\n",
    "    Eg: Lets say IXZ was an uncovered airport, we add all flights originating and departing from this airport to updated_flight_legs\n",
    "    4. While adding a flight to updated_flight_legs, we need to make sure that its not already there. Duplicates cause \n",
    "    huge problems while creating coverage matrices and then later on solving them.\n",
    "    5. Return the updated_flight_legs\n",
    "\n",
    "    \"\"\"\n",
    "    uncov_airports=[]\n",
    "    cov_indices=[]\n",
    "    upd_indices=[]\n",
    "    for k,v in flight_coverage_status.items():\n",
    "        if v==False:\n",
    "            updated_flight_legs.append(legs[k])\n",
    "            uncov_airports.append(legs[k].origin)\n",
    "            uncov_airports.append(legs[k].destination)\n",
    "            cov_indices.append(k)\n",
    "            upd_indices.append(k)\n",
    "    uncov_airports=list(set(uncov_airports))\n",
    "    all_airports,airport_arr_flights,airport_dep_flights=return_all_airports_dep_arr(global_flight_legs_copy.copy())\n",
    "    if len(updated_flight_legs)<K and main_iter%5==0:\n",
    "        for airport in uncov_airports:\n",
    "            for flight in airport_arr_flights[airport]:\n",
    "                if flight.index not in cov_indices and flight.index not in upd_indices:\n",
    "                    updated_flight_legs.append(flight)\n",
    "                    upd_indices.append(flight.index)\n",
    "            for flight in airport_dep_flights[airport]:\n",
    "                if flight.index not in cov_indices and flight.index not in upd_indices:\n",
    "                    updated_flight_legs.append(flight)\n",
    "                    upd_indices.append(flight.index)\n",
    "    return updated_flight_legs\n",
    "def new_coverage_matrix_and_legs(coverage,flight_legs_chosen):\n",
    "    \"\"\"\n",
    "    1. This takes in as input(coverage,flight_legs_chosen)\n",
    "    2. Remember coverage has the following format-> (False, old_coverage_matrix, list of uncovered flight indices)\n",
    "    3. Using the old_coverage_matrix, and uncovered_flight_index... we do the following\n",
    "        3.1. We form an empty matrix called new_coverage_matrix. Note in the below code we have not started with any predefined size\n",
    "        3.2. We then loop through the old_coverage_matrix s' rows\n",
    "        3.3. If the index is in uncovered_flight_indices, then do not add the corresponding row into new_coverage_matrix\n",
    "        3.4. Correspondingly, if the index is not in uncovered_flight_indices, add the corresponding row from old_coverage_matrix\n",
    "        and the corresponding flight index into new_flight_legs\n",
    "    4. This function s' main purpose is to prepare the new_coverage_matrix and the new_flight_legs_covered for purpose of IP CPLEX Optimization\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    uncovered_flight_indices=coverage[2]\n",
    "    old_coverage_matrix=coverage[1].copy()\n",
    "    new_coverage_matrix=[]\n",
    "    new_flight_legs_covered=[]\n",
    "    for i in range(len(old_coverage_matrix)):\n",
    "        if i not in uncovered_flight_indices:\n",
    "            new_coverage_matrix.append(old_coverage_matrix[i].copy())\n",
    "            new_flight_legs_covered.append(flight_legs_chosen[i])\n",
    "    return new_flight_legs_covered,new_coverage_matrix\n",
    "\n",
    "\n",
    "def init_for_solving_CPLEX(new_flight_legs_covered):\n",
    "    \"\"\"\n",
    "    Using the flight_legs, the leg_to_index_mapper, and index_to_leg_mapper, arrival and departure flights, adjacency matrix of connections\n",
    "    ,create duties and then create 1 day pairings, 2 day pairings and then create coverage matrix. All these components\n",
    "    are needed for CPLEX Solving\n",
    "    \"\"\"\n",
    "    flight_legs_chosen=new_flight_legs_covered.copy()\n",
    "    leg_to_index_mapper=create_leg_to_index_mapper(flight_legs_chosen)\n",
    "    index_to_leg_mapper=create_index_to_leg_mapper(flight_legs_chosen)\n",
    "    all_airports,airport_arr_flights,airport_dep_flights=return_all_airports_dep_arr(flight_legs_chosen)\n",
    "    adjacency_matrix_of_connections=create_adjacency_matrix(flight_legs_chosen)\n",
    "    dg=generate_duties(all_airports,airport_dep_flights,adjacency_matrix_of_connections,leg_to_index_mapper,flight_legs_chosen)\n",
    "    pg=PairingsGenerator()\n",
    "    pg.generate_2_day_pairings(dg.duty_list)\n",
    "    pg.generate_1_day_pairings(dg.duty_list)\n",
    "    coverage=coverage_checker(pg,leg_to_index_mapper,flight_legs_chosen)\n",
    "    return flight_legs_chosen,leg_to_index_mapper,index_to_leg_mapper,all_airports,airport_arr_flights,airport_dep_flights,adjacency_matrix_of_connections,dg,pg,coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964d204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncov_airports_not_in_cb(flight_coverage_status,legs):\n",
    "    \"\"\"\n",
    "    For the purpose of printing the status, in each divide and cover iteration, this function is used.\n",
    "    It basically takes all legs having a False indicator in the flight_coverage_status and \n",
    "    then checks if the origin is in crew base->if not add it to uncov airports\n",
    "    and similarly checks for the destination.\n",
    "\n",
    "    \"\"\"\n",
    "    cb=PairingsGenerator().crew_base\n",
    "    uncov_airports=set()\n",
    "    for k,v in flight_coverage_status.items():\n",
    "        if v==False:\n",
    "            if legs[k].origin not in cb:\n",
    "                uncov_airports.add(legs[k].origin)\n",
    "            if legs[k].destination not in cb:\n",
    "                uncov_airports.add(legs[k].destination)\n",
    "    return list(set(uncov_airports))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dbf121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def controller_update_flight_coverage_status(old_cov_status,new_cov_status):\n",
    "    \"\"\"\n",
    "    This function is used in the divide and cover controller function\n",
    "    Basically, the divide and controller function calls divide and cover function many times.\n",
    "    In each iteration, new sets of pairings are generated covering different sets of flight indices\n",
    "    This covering is then updated in old(original)_cov_status. \n",
    "    Note in the controller, only if the original flight coverage status all take values True, then only\n",
    "    the algorithm/While loop is stopped.\n",
    "    \"\"\"\n",
    "    for k,v in new_cov_status.items():\n",
    "        if v==True:\n",
    "            old_cov_status[k]=True\n",
    "    return old_cov_status\n",
    "def divide_and_cover_controller(K,legs):\n",
    "    \"\"\"\n",
    "    This function controls the divide and cover sub function. It runs many independent iterations of divide and cover\n",
    "    each of which already execute 300 iterations(or count=main_iter set inside function) so that uncovered flights\n",
    "    can be quickly covered\n",
    "    \"\"\"\n",
    "    flight_coverage_status=create_flight_coverage_status(legs)\n",
    "    global_flight_legs_copy=legs.copy()\n",
    "    updated_flight_legs=legs.copy()\n",
    "    PG=[]\n",
    "    pg=PairingsGenerator()\n",
    "    pg.generate_short_round_trip_pairings(legs)\n",
    "    flight_coverage_status=init_update_flight_coverage_status(pg.pairings,flight_coverage_status)\n",
    "    PG=init_update_pairing_list(pg.pairings,PG)\n",
    "    no_of_div_cover_iterations=10\n",
    "#     for i in range(no_of_div_cover_iterations):\n",
    "    while list(flight_coverage_status.values()) != [True]*len(flight_coverage_status.values()):\n",
    "        new_result=divide_and_cover_new(K,legs)\n",
    "        new_pairings=new_result[0]\n",
    "        new_status=new_result[1]\n",
    "        flight_coverage_status=controller_update_flight_coverage_status(flight_coverage_status,new_status)\n",
    "        PG=init_update_pairing_list(new_pairings,PG)\n",
    "        print(\"Controller @@@@@ Current Status::: True=\",list(flight_coverage_status.values()).count(True),\"False=\",list(flight_coverage_status.values()).count(False))\n",
    "    return PG\n",
    "\n",
    "def unique_flights_creator(airports_list,flights_list_by_airport,flt_list=[],flt_indices_list=[]):\n",
    "    \"\"\"\n",
    "    This takes into 2 inputs as params(airports_list:Consists of airports, and flights_list_by_airport:\n",
    "    Consists of flights by airports).\n",
    "    \n",
    "    flt_indices_list:consisting of indices of flights and flt_list:consisting of flights are either passed \n",
    "    as parameters or empty lists are used as default parameters\n",
    "    \n",
    "    The main role of this function is to remove duplicates\n",
    "    \n",
    "    There are many \"search reduction heuristics\" in divide_and_cover function. In order to optimize this\n",
    "    flight_leg_chosen space keeps changing. In order to make sure that no duplicates enter this space\n",
    "    (Again, duplicates cause problems in coverage_matrix generation and then subsequent IP CPLEX Solving),\n",
    "    this function is implemented\n",
    "    \"\"\"\n",
    "\n",
    "    for airport in airports_list:\n",
    "        for leg in flights_list_by_airport[airport]:\n",
    "            if leg.index not in flt_indices_list:\n",
    "                flt_indices_list.append(leg.index)\n",
    "                flt_list.append(leg)\n",
    "\n",
    "    return flt_indices_list,flt_list\n",
    "\n",
    "def unique_airports_creator(all_airports_list,excluding_airports_list):\n",
    "    \"\"\"\n",
    "    Takes in 2 inputs(all_airports_list and excluding_airports_list:the airports that need to be excluded)\n",
    "    We form 2 lists, wherein airports that exist in all_airports_list and not existing in excluding_airports_list is,\n",
    "    appended into focus_airports_list\n",
    "    and airports that do exist in excluding_airports_list is put in non_focus_airports_list\n",
    "    \"\"\"\n",
    "    focus_airports_list=[]\n",
    "    non_focus_airports_list=[]\n",
    "    for airport in all_airports_list:\n",
    "        if airport not in excluding_airports_list:\n",
    "            focus_airports_list.append(airport) \n",
    "        else:\n",
    "            non_focus_airports_list.append(airport)\n",
    "    return focus_airports_list,non_focus_airports_list\n",
    "            \n",
    "\n",
    "def unique_flights_creator_random_type(exist_flights_indices,exist_flights_list,K,flights_list):\n",
    "    \"\"\"\n",
    "    This follows the same core concept as unique_flights_creator,\n",
    "    However, due to the addition of a random_flight_index_generated element, things slightly change while programming and checking\n",
    "    Input: ()\n",
    "    This function again, sends a duplicate free list of indices and flights\n",
    "    \"\"\"\n",
    "    iter_=0\n",
    "    while len(exist_flights_list)!=K and iter_<30:\n",
    "        r=random.randint(0,len(flights_list)-1)\n",
    "        if flights_list[r].index not in exist_flights_indices:\n",
    "            exist_flights_list.append(flights_list[r])\n",
    "            exist_flights_indices.append(flights_list[r].index)\n",
    "        iter_+=1\n",
    "    return exist_flights_list,exist_flights_indices\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f13f7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_and_cover_new(K,legs):\n",
    "    \"\"\"\n",
    "    This is the divide and cover function that executes main_iter no of iterations. It stops either if the main_iter \n",
    "    count is reached or if all flights have been covered. Some search heuristics have been deployed if the no. of flights \n",
    "    to be covered reduces and try as fast as possible to cover them quickly.\n",
    "    \"\"\"\n",
    "    flight_coverage_status=create_flight_coverage_status(legs)\n",
    "    global_flight_legs_copy=legs.copy()\n",
    "    updated_flight_legs=legs.copy()\n",
    "    \n",
    "    \n",
    "    PG=[]\n",
    "    retry_iter=0\n",
    "    global_retry_iter=0\n",
    "    main_iter=0\n",
    "    \n",
    "    \n",
    "    while list(flight_coverage_status.values())!=[True]*len(flight_coverage_status.values()) and main_iter<300:\n",
    "        if len(updated_flight_legs)<K:\n",
    "            if list(flight_coverage_status.values()).count(False)>20:\n",
    "                if global_retry_iter>10:\n",
    "                    updated_flight_legs=global_flight_legs_copy.copy()\n",
    "                    flight_legs_chosen=random.sample(updated_flight_legs,K)\n",
    "                    global_retry_iter=0\n",
    "                else:\n",
    "                    flight_legs_chosen=updated_flight_legs.copy()\n",
    "            else:\n",
    "                \n",
    "                if list(flight_coverage_status.values()).count(False)<5:\n",
    "                    all_airports,airport_arr_flights,airport_dep_flights=return_all_airports_dep_arr(flight_legs_chosen)\n",
    "                    tpgcb=PairingsGenerator().crew_base\n",
    "                    crucial_airports=[]\n",
    "                    non_crucial_airports=[]\n",
    "                    crucial_airports,non_crucial_airports=unique_airports_creator(all_airports,tpgcb)\n",
    "                    crucial_airports=list(set(crucial_airports))\n",
    "                    non_crucial_airports=list(set(non_crucial_airports))\n",
    "                    slightly_imp_indices,slightly_imp=unique_flights_creator(crucial_airports,airport_arr_flights)\n",
    "                    slightly_imp_indices,slightly_imp=unique_flights_creator(crucial_airports,airport_dep_flights,slightly_imp,slightly_imp_indices)\n",
    "                    if len(slightly_imp)<K:\n",
    "                        if random.random()<0.5:\n",
    "                            non_crucial_flt_indices,non_crucial_flights=unique_flights_creator(non_crucial_airports,airport_dep_flights)\n",
    "                            slightly_imp,slightly_imp_indices=unique_flights_creator_random_type(slightly_imp_indices,slightly_imp,K,non_crucial_flights)\n",
    "                            if len(slightly_imp)<K:\n",
    "                                slightly_imp,slightly_imp_indices=unique_flights_creator_random_type(slightly_imp_indices,slightly_imp,K,legs)\n",
    "                        else:\n",
    "                            if len(slightly_imp)<K:\n",
    "                                slightly_imp,slightly_imp_indices=unique_flights_creator_random_type(slightly_imp_indices,slightly_imp,K,legs)\n",
    "                    flight_legs_chosen=slightly_imp.copy()\n",
    "                    updated_flight_legs=flight_legs_chosen.copy()\n",
    "                else:\n",
    "                    imp_flt_indices=[]\n",
    "                    for k,v in flight_coverage_status.items():\n",
    "                        if v==False:\n",
    "                            imp_flt_indices.append(k)\n",
    "                    flight_legs_chosen=[]\n",
    "                    for i in imp_flt_indices:\n",
    "                        flight_legs_chosen.append(legs[i])\n",
    "                    flight_legs_chosen,imp_flt_indices=unique_flights_creator_random_type(imp_flt_indices,flight_legs_chosen,K,legs)\n",
    "                    updated_flight_legs=flight_legs_chosen.copy()\n",
    "                    \n",
    "            global_retry_iter+=1\n",
    "        else:\n",
    "            flight_legs_chosen=random.sample(updated_flight_legs,K)\n",
    "            \n",
    "            \n",
    "        if len(flight_legs_chosen)>K:\n",
    "            flight_legs_chosen=random.sample(flight_legs_chosen,K)\n",
    "            \n",
    "        if global_retry_iter>20:\n",
    "            global_retry_iter=0\n",
    "            flight_legs_chosen=random.sample(global_flight_legs_copy,K)\n",
    "        flight_legs_chosen,leg_to_index_mapper,index_to_leg_mapper,all_airports,airport_arr_flights,airport_dep_flights,adjacency_matrix_of_connections,dg,pg,coverage=init_for_solving_CPLEX(flight_legs_chosen.copy())\n",
    "        \n",
    "        if coverage[0]==False or len(pg.pairings)<2:\n",
    "            while coverage[0]==False:\n",
    "                if len(flight_legs_chosen)==0:\n",
    "                    break\n",
    "                new_flight_legs_covered,new_coverage_matrix=new_coverage_matrix_and_legs(coverage,flight_legs_chosen.copy())\n",
    "                flight_legs_chosen,leg_to_index_mapper,index_to_leg_mapper,all_airports,airport_arr_flights,airport_dep_flights,adjacency_matrix_of_connections,dg,pg,coverage=init_for_solving_CPLEX(new_flight_legs_covered.copy())\n",
    "                  \n",
    "            sol,airline_cp_model,x=create_and_solve_model(pg,leg_to_index_mapper,flight_legs_chosen,IP=True)\n",
    "            \n",
    "            if sol is None:\n",
    "                continue\n",
    "            else:\n",
    "                pairing_solution_indices=return_pairing_information(pg,airline_cp_model,x).copy()\n",
    "                PG=update_pairing_set(PG,pg,pairing_solution_indices,legs,index_to_leg_mapper,leg_to_index_mapper).copy()\n",
    "                flight_coverage_status=update_flight_coverage_status(flight_coverage_status,flight_legs_chosen)\n",
    "                \n",
    "        else:\n",
    "            sol,airline_cp_model,x=create_and_solve_model(pg,leg_to_index_mapper,flight_legs_chosen,IP=True)\n",
    "            if sol is None:\n",
    "                continue\n",
    "            else:\n",
    "                pairing_solution_indices=return_pairing_information(pg,airline_cp_model,x).copy()\n",
    "                PG=update_pairing_set(PG,pg,pairing_solution_indices,legs,index_to_leg_mapper,leg_to_index_mapper).copy()\n",
    "                flight_coverage_status=update_flight_coverage_status(flight_coverage_status,flight_legs_chosen)\n",
    "        \n",
    "        updated_flight_legs=[]\n",
    "        if main_iter%10==0:\n",
    "            updated_flight_legs=update_flight_list(updated_flight_legs,legs,global_flight_legs_copy,flight_coverage_status,K,main_iter)\n",
    "        \n",
    "\n",
    "        print(\"Current Status::: True=\",list(flight_coverage_status.values()).count(True),\"False=\",list(flight_coverage_status.values()).count(False),\"RETRY ITER\",retry_iter,\"GLOBALRETRYITER\",global_retry_iter,\"MAIN ITER\",main_iter)\n",
    "        print(\"UNCOVERED AIRPORT :::: \",uncov_airports_not_in_cb(flight_coverage_status,legs))\n",
    "        main_iter+=1\n",
    "\n",
    "    return (PG,flight_coverage_status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df2086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.read_csv(r\"C:\\Users\\Acer Pc\\Desktop\\UltimateAir\\UltimateAirUpdatedPBIX.csv\")\n",
    "df=pd.read_csv(r\"Indigo_Schedule.csv\")\n",
    "legs=create_legs_object(df,days=2)\n",
    "PG=divide_and_cover_controller(200,legs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e623de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def CG_stopper(CG_tracker):\n",
    "    \"\"\"\n",
    "    If False is returned by CG_stopper, then continue CG iterations\n",
    "    Else if True returned, stop!\n",
    "    \"\"\"\n",
    "    if len(CG_tracker)==0 or len(CG_tracker)==1:\n",
    "        return False\n",
    "    else:\n",
    "        if len(CG_tracker[-2][0].pairings)-len(CG_tracker[-1][0].pairings) == 0:\n",
    "            # No pairings added\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "def get_duties_reduced_costs(duty_list):\n",
    "    temp=[]\n",
    "    for duty in duty_list:\n",
    "        temp.append(duty.duty_reduced_cost)\n",
    "    return temp.copy()\n",
    "def column_generation(PG,dg,duty_network,crew_bases_indices,s_nodes_dict,t_nodes_dict):\n",
    "    \"\"\"\n",
    "    Each step is briefly highlighted in the below lines.\n",
    "    Overall, column generation keeps running and adds columns by calling SPPRC until a negative reduced cost column \n",
    "    is not available for addition.\n",
    "    Do note that a PG list enters into column_generation as a parameter. PG contains the divide_and_cover related \n",
    "    distribution of pairings that covers all flights\n",
    "    \n",
    "    \"\"\"\n",
    "    #1. Starting off\n",
    "    #df=pd.read_csv(r\"C:\\Users\\Acer Pc\\Desktop\\UltimateAir\\UltimateAirUpdatedPBIX.csv\")\n",
    "    df=pd.read_csv(r\"Indigo_Schedule.csv\")\n",
    "    legs=create_legs_object(df,days=2)\n",
    "    legs=legs\n",
    "    all_airports,airport_arr_flights,airport_dep_flights=return_all_airports_dep_arr(legs)\n",
    "    adjacency_matrix_of_connections=create_adjacency_matrix(legs)\n",
    "    leg_to_index_mapper=create_leg_to_index_mapper(legs)\n",
    "    index_to_leg_mapper=create_index_to_leg_mapper(legs)\n",
    "    \n",
    "    \n",
    "    #2. Performing Divide and Cover Heuristic->This would have been performed outside of CG and fed into this method\n",
    "#     PG=divide_and_cover_new(300,legs,[])\n",
    "#     print(len(PG))\n",
    "#     return PG,legs\n",
    "    pg=PairingsGenerator(PG)\n",
    "    CG_tracker=[]\n",
    "    #RCT Stands for Reduced costs tracker\n",
    "    RCT=[]\n",
    "#     return pg,legs\n",
    "    \n",
    "    print(\"Duty Generation Started\")\n",
    "    #3. Generating Duty List\n",
    "#     dg=generate_duties(all_airports,airport_dep_flights,adjacency_matrix_of_connections,leg_to_index_mapper,legs)\n",
    "    print(\"DutyGeneration Completed\")\n",
    "    \n",
    "    #--Here we are setting termination criteria to 10 iterations\n",
    "    no_of_iterations=10\n",
    "    \n",
    "    #4. Form Duty Network\n",
    "    crew_bases=pg.crew_base\n",
    "    print(\"Duty Network Creation Started\")\n",
    "    #duty_network,crew_bases_indices,s_nodes_dict,t_nodes_dict=form_duty_network(dg,crew_bases)\n",
    "    print(\"Duty Network Creation Ended\")\n",
    "    \n",
    "    #5. Column Generation Procedure\n",
    "    print(\"CG Started\")\n",
    "    while CG_stopper(CG_tracker)!=True:\n",
    "        sol,airline_cp_model,x=create_and_solve_model(pg,leg_to_index_mapper,legs)\n",
    "        print(sol.get_objective_value())\n",
    "        existing_pg_list=pg.pairings.copy()\n",
    "        pairing_solution_indices,dual_values=default_model_return_function(sol,airline_cp_model,x,pg)\n",
    "        CG_tracker.append((pg,sol,airline_cp_model,x,pairing_solution_indices.copy(),dual_values.copy(),dg.duty_list.copy()))\n",
    "        RCT.append(get_duties_reduced_costs(dg.duty_list).copy())\n",
    "        dg=modify_duty_costs(dual_values,dg)\n",
    "        for airport_letter_code,airport_tuple in crew_bases_indices.items():\n",
    "            labels=SPPRC(airport_letter_code,duty_network,crew_bases_indices,s_nodes_dict,t_nodes_dict,dg)\n",
    "            existing_pg_list=process_labels_and_collect_pairings(existing_pg_list,labels,dual_values).copy()\n",
    "            pg=PairingsGenerator(existing_pg_list.copy())\n",
    "    return (CG_tracker,RCT)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb6f62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda1243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"Indigo_Schedule.csv\")\n",
    "legs=create_legs_object(df,days=2)\n",
    "legs=legs\n",
    "all_airports,airport_arr_flights,airport_dep_flights=return_all_airports_dep_arr(legs)\n",
    "adjacency_matrix_of_connections=create_adjacency_matrix(legs)\n",
    "leg_to_index_mapper=create_leg_to_index_mapper(legs)\n",
    "index_to_leg_mapper=create_index_to_leg_mapper(legs)\n",
    "dg=generate_duties(all_airports,airport_dep_flights,adjacency_matrix_of_connections,leg_to_index_mapper,legs)\n",
    "pg=PairingsGenerator(PG)\n",
    "crew_bases=pg.crew_base\n",
    "duty_network,crew_bases_indices,s_nodes_dict,t_nodes_dict=form_duty_network(dg,crew_bases)\n",
    "with open(\"DutyNetwork.txt\",\"w\") as f:\n",
    "    f.write(str(duty_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c643685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PG_copy=PG.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a26eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "duty_network=list(duty_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d32b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(duty_network)):\n",
    "    duty_network[i]=np.array(duty_network[i])\n",
    "print(duty_network[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d67ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DutyNetwork.txt\",\"w\") as f:\n",
    "    f.write(str(duty_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fb8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "CG_tracker=column_generation(PG,dg,duty_network,crew_bases_indices,s_nodes_dict,t_nodes_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b315f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=[[1,2,3,4],[1,2,3,4]]\n",
    "with open(\"Temp.txt\",\"w\") as f:\n",
    "    f.write(str(l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baacdb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=coverage_checker(PairingsGenerator(PG),create_leg_to_index_mapper(legs),legs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b6d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=[]\n",
    "for item in CG_tracker[-1]:\n",
    "    f.append(item)\n",
    "data=[]\n",
    "for item in f:\n",
    "    data.append([])\n",
    "    for d in item:\n",
    "        data[-1].append(d)\n",
    "import numpy as np\n",
    "data=list(np.array(data).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5938c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def print_table(data):\n",
    "    if not data:\n",
    "        print(\"The data is empty.\")\n",
    "    else:\n",
    "        headers = [\"Column 1\", \"Column 2\", \"Column 3\", \"Column 4\"]  # Adjust column headers as needed\n",
    "\n",
    "        # Use the \"tabulate\" function to format and print the table\n",
    "        print(tabulate(data, headers=headers, tablefmt=\"pretty\"))\n",
    "\n",
    "\n",
    "print_table(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d176b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1740d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76daac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f245353",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c=[1,2]\n",
    "class ABC:\n",
    "    def __init__(self,l):\n",
    "        self.l=l\n",
    "a=ABC(c)\n",
    "b=ABC(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f942d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_to_index_mapper=create_leg_to_index_mapper(legs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de59668",
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_to_index_mapper[179]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4eb812",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a54f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c354854f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a62fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e2e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84632b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf72bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ad79ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b769174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7f6445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fa5ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ddb14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9384e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43db003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caea2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d71d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1fab88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee0fd79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090ea1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a22ea8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a3f7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a888a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d3b2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3459a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2a48e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3b254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7656ce8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d7779c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b362f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3a6296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e889207d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff46bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a1457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81442dd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc499b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8974e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb79508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284c4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e15913a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b1a311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde5940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48508563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40384ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e34e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a92653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3f60fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f7786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c43a3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e941cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869fa277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8968c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4f7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210cda94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc4ec1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add69c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c75201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106970a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1636cef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc43a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627c4958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0431b2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bb65a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe731f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cf7a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae39402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de51b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e1417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471276a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96070b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e166490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb802aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a8831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605ecc1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43681a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424df6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0961c231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ccb5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
